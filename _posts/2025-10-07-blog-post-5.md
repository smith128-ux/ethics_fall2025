---
title: 'SOC Blog 1: Data & Society Databites Talk'
date: 2025-10-07
permalink: /posts/2025/10/blog-post-5/
tags:
  - GenAI
  - SOC blog post 1
  - Ethics
---

**Databite No. 158:**  
[Databite No. 158: Adaptation | Generative AI's Labor Impacts](https://www.youtube.com/watch?v=EI4rdxJLqrA&list=PLYrf5LyVCF1Nk28nRu8lcCIxtAH3iVGDj)
---

***Adaptation***
Replaceability. What does it mean to be replaceable? With the furthered development of generative AI models, replaceability is a big fear. The advancement of AI models spells an ominous future for the stability of a lot of jobs. This weekend, I watched and analyzed an episode of the Data & Society Research Institute’s Databite series, specifically Databite No. 158: Adaptation, a conversation on Generative AI’s labor impacts. It was a fascinating hour-long watch, and despite being released April 23, 2024, this topic still holds largely relevant.
	
In this conversation, with host Aiha Nguyen, Jeff Freitas, Quinten Steenhaus, and Livia Garofalo discuss navigating through this new “AI-age” and the social, political, cultural, and technological challenges that it brings with it. For a quick background, Jeff Freitas is a longtime math teacher and also the president of the California Federation of Teachers (CFT). Quinten Steenhaus is a legal scholar with a background in law and computer science. Steenhaus is a legal scholar and the co-director of Suffolk University’s Law School Legal Innovation and Technology Lab. Lastly, Livia Garofalo is a researcher for Data & Society and has spent the last year researching the relationship between AI,therapists and their clients.

What I find most interesting is how everyone's unique backgrounds and positions seem to converge together on a singular issue. With the immense usefulness of this technology, how does it threaten to replace us? All three of the speakers vocalize their fears on AI replacing teaching, law, and therapy, each with their own unique perspectives. Freitas views AI through the lens of a teacher. His initial impression was that AI could be used as a fancy calculator. As AI started advancing, Freitas asked two questions. How do we identify and address students' use of AI? And how can abuse of this technology, the cheating, be prevented? It's a very useful technology that has a highly destructive potential. Freitas also talks about the uses of AI for menial tasks, such as answering emails. Though Freitas warns that use of AI in those ways can inhibit thought and critical thinking. There’s also the privacy concerns of well, are my emails being saved into a data set?

Steenhuis comes at this issue from the point of view of a lawyer and computer scientist. Who’re the people we’re helping? How can this technology be used to help people who cannot afford legal help? According to Steenhuis, despite it seeming like there is an abundance of lawyers, only around 8% of the legal needs of the poor are met. 92% of those cases are left unaddressed. And overall, 2/3 of legal issues are unaddressed. Can AI be used to help those in need? Aside from defendants, lawyers have begun using AI to their advantage. In some cases, AI has even been misused like in the case of Trump’s lawyers creating documents with fake citations, and some generative AI models generating misleading information. Steenhuis argues these tools should have “guardrails”

Garofalo offers the perspective of therapists on AI. As Garofalo puts it, algorithmic systems are a path of how people receive care and get delivered care. Ai is being implemented in both medical care and psychotherapeutic interactions. Garofalo spent a year interviewing mental health providers and their view on how it might come to replace traditional therapists someday. Already, AI is being perceived and used for client/therapist matching, and other management aspects. People have also started to seek chatbots for therapeutic conversation. In a similar sense to how AI can help with access to justice, AI can provide access to generated “therapy sessions”. Professionals in the field are trying to reckon with this new era of “auto-intimacy.” What does it mean to be in a relationship with a chat bot? I know from my own personal experience, people have begun to form deep, albeit superficial relationships with AI chat bots. As the mental health crisis begins to snowball, I see more and more people turning to GenAI for help. I worry what that might bring about, as AI is mostly designed to agree obediently, whereas a licensed therapist can provide curated advice for a person's specific needs.

If I could ask a single question to the speakers of this episode I would ask this, “As AI has begun to permeate itself into various facets of life, at what point do we take a step back and evaluate what should and should not be integrated?” I ask this question for a simple reason. In my opinion, many things do not require AI. At this point, I believe AI is the new “shiny toy” in the tech-sphere. It’s the new kid on the block. It’s hot. As a result, many institutions are eager to hop on the GenAI train. What I think is ignored, is the lack of testing and knowledge on the inner workings of GenAI models. Many AI models are Black Box models, which means that internal logic is often obscured and not fully understood. The only certainties are the input and output. At what point should we ask, “how far should we go with AI integration?”

So what? This talk explores the layered relationship that professionals and workers have with the technology that dictates their everyday life. Between all three speakers, the sentiment of replaceability is shared. While the common person seeks AI for help, there's a serious devaluation of expertise. As AI continues to be developed, I believe it will start to be used to answer the problem of widespread staffing shortages. From customer service to healthcare.

***Reflection***
This was a very densely packed, one hour conversation. It made me reflect on the common sentiment shared by most of my friends and family over the last years, is that AI can and could replace them in their field. Expertise and education is seemingly being devalued as there's an increased push for AI. Even though Freitas, Steenhuis, and Garofalo come from varyingly different backgrounds, they all share their concerns over AI’s versatility being a threat to job stability. How will AI replace me as a computer scientist and Japanese linguist? It’s not hard to imagine with CoPilot being used to code entire programs, and Google AI being able to listen and translate on the fly. Where is AI’s place in society? Does it even have a place, and should we be welcoming? Ultimately, AI is a tool, a tool I regret was ever brough into existence, but a tool nonetheless. A tool is how you use it. Like a kitchen knife can be used for murder, it can also be used to cook gourmet meals. AI should be used wisely, and not incorporated homogeneously into any system. 

Thank you. I hope you enjoyed this blog post! : - ) 
-tony Smith
