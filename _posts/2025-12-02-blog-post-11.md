---
title: 'PRIV Blog 1: Complete Delete'
date: 2025-12-02
permalink: /posts/2025/12/blog-post-11/
tags:
  - Privacy
  - PRIV blog post 1
  - Ethics
---
**Case Study**  
[Complete Delete: In Practice, Clicking 'Delete' Rarely Deletes. Should it?](https://mit-serc.pubpub.org/pub/fesqymtr/release/3?readingCollection=ca73f7c0)

This week I read “Complete Delete: In Practice, Clicking ‘Delete’ Rarely Deletes. Should it?”, written by Simson Garfinkel, about the different ways that systems go about deleting data and how that can potentially danger privacy. This case study identifies a key paradox in this argument: information is hard to delete, yet information is difficult to retain. When it comes to deletion, software developers use one of four policies. Never delete, Indeterminate deletion, Local complete delete, and Global complete delete. These policies have different methods of ‘deleting’ information with differing levels of efficiency and ‘Complete’-ness. To better understand the contents of this case study, I chose four of the discussion questions provided at the end of the reading to answer.

Propose approaches for informing users of the existence of remnant data on their systems. The biggest issue in deleting files is the lack of transparency on how said files are being deleted. I don’t think it’s entirely up to the user to learn how their deleted files are being handled. When deleting files, it would be beneficial to have a popup detailing what the system is going to do. If the system says, “I will hold onto these files indefinitely or for a short period of time in case of accidental deletion,” users should be given the option to opt out of that. If a user wants to hold onto deleted files, they should also be allowed to specify how long those files should be stored.

Compare the advantages of deleting information with information permanence. Getting rid of things is difficult. Sometimes we think we really want to get rid of something and then once it’s gone, we regret it. This regret is understandably pretty hard to deal with. It’s because of this pain that we might be drawn to information permanence, the idea that even information that isn’t readily available, that information is still recoverable. Holding onto every piece of information is expensive, and sometimes a threat to privacy. What if you’re trying to delete sensitive information? If you didn’t mean to delete it, that could cause a lot of trouble. But what if you meant to delete it, completely, and now there's the possibility some perpetrators can recover that information and weaponize it.

Object overwriting is a straightforward, well-understood approach for eliminating the ability to recover deleted data. However, software engineers have not made object overwriting mandatory on today’s computer systems because it would negatively impact performance and battery life. This is a decision that must be made at the system level; it cannot be made a user option. Do you think that systems should employ object overwriting, or do you think that the current approach of not overwriting is correct? I think we’re at a point where computers are so fast, so efficient, and so large that we can’t be worried about these sorts of things. Pennies on the dollar. Object overwriting is a tried and tested method for scratching over old data and assuring that it can’t be recovered. I doubt that the negative impact would be noticeably significant, especially when the benefits are a more reliable method of ‘complete deletion’. If we want to use a really smart approach for deletion then encryption and key-usage would be the route to go. This ensures that unless you have the key necessary to encrypt a file, that file is good as gone, lost to the ether. Though, I wonder if these ‘lost’ files can still be recovered. Even if we use object overwriting or encryption, just because we’ve deleted the original file doesn’t guarantee that we’ve gotten rid of every instance of that file.

Some US policymakers believe that it should be possible for the US government to be able to access the encrypted contents of phones and other devices, but at the same time, they want US devices protected against foreign governments such as the governments of Russia, China, and Iran. US companies have responded that any capabilities that would be made available to the US government would have to be made available to other governments as well, resulting in systems that are less secure for everyone. Argue one position or the other. Personally, I don’t think it’s fair to ask developers to make it so that you and only YOU can access peoples sensitive information. It’s childish. If the US government wants to access encrypted data, then they should be prepared for everyone else to access that same data. Either that, or we continue on our way and nobody can access people’s information.

In response to these discussion questions, I would like to provide my own for consideration:
How should the matter of archived data be handled? Should people be able to opt out of having their data archived?
I asked this question because I think there was a serious lack of archiving talked about in this case study. The threat of information and files being deleted has led to groups of people making it their duty to archive and preserve tons of digital information. How should we handle this preservation?

This was an incredibly interesting read, short, concise, and very straight-forward. I had no idea there was more to deleting files than just simply deleting them. The ethical concerns raised in this article were very interesting, and I never thought about the trade off of retaining ‘deleted’ information. I remember as a kid I accidentally deleted a Minecraft world of great significance to me. Oh man, I was upset. I wish I could’ve recovered it, and maybe I could have. Makes me think about how everything on my computer is stored, and where it all goes.

Thank you for reading! 
-tony